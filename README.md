# Natural_Language-_Processing
NLP Projects for Sentiment Analysis and Neural Machine Translation

This is the first indpeth deep-dive into Neural Machine Translation using LSTM without an attention mechanism with Tensorflows.
The goal was to map a sequence-2-sequence. The goal was achieved without having to use attaention with a perplexity value of 1 at ~5 epochs of training.

The NLP project on sentiment analysis explored the use of CNN, bidirectional(LSTM), GRU for sentiment analysis and mapping to a continuous domain with the aim of investigating loss and mean absolute error performance amongst all archutectures.

The Gated Recurrent Unit (GRU) was found to give the most optimum performance having less number of trainable parameter and for the same epoch of training was found to give a better loss and mae value than CNN and biLSTM.

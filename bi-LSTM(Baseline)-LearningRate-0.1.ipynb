{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taiwoalabi/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#This code is to implement RNN (Recurrent Neural Networks for sentiment analysis)\n",
    "from keras.layers.recurrent import LSTM\n",
    "\n",
    "from keras.layers.core import Dense, Dropout, SpatialDropout1D, Activation\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.pooling import GlobalMaxPooling1D\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gensim, logging\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_FILE = \"/Users/taiwoalabi/Downloads/winemag-data-130k-v2.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Marie= pd.read_csv(INPUT_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Marie[\"Feature1\"] = []\n",
    "for ii in range(len(Marie)):\n",
    "    \n",
    "    Marie.loc[ii,\"Feature1\"] = str(Marie.loc[ii,\"description\"]) + \",\" + str(Marie.loc[ii,\"country\"]) + \",\" + str(Marie.loc[ii,\"province\"]) \\\n",
    "    + str(Marie.loc[ii,\"variety\"]) + \",\" + str(Marie.loc[ii,\"winery\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Adjective_Nouns= ['JJ', 'JJR','JJS','NN', 'NNS', 'NNP', 'NNPS', 'VBN' ]\n",
    "for ii in range(len(Marie)):\n",
    "    Z= nltk.pos_tag(nltk.word_tokenize(Marie.loc[ii, \"description\"]))\n",
    "    ZZ= [ii[0] for ii in Z if ii[1] in Adjective_Nouns]\n",
    "    Marie.loc[ii,\"POS-Tag\"]= ' '.join(ZZ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 5000\n",
    "EMBED_SIZE = 500\n",
    "NUM_FILTERS = 1024\n",
    "NUM_WORDS = 70\n",
    "BATCH_SIZE = 100\n",
    "NUM_EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = collections.Counter()\n",
    "maxlen = 0\n",
    "for iii in range(len(Marie)):\n",
    "    sentence = Marie['POS-Tag'][iii]\n",
    "    words = [x.lower() for x in nltk.word_tokenize(sentence)]\n",
    "    \n",
    "    if len(words) > maxlen:\n",
    "        maxlen = len(words)\n",
    "    for word in words:\n",
    "        counter[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2index = collections.defaultdict(int)\n",
    "for wid, word in enumerate(counter.most_common(VOCAB_SIZE)):\n",
    "    word2index[word[0]] = wid + 1\n",
    "vocab_size = len(word2index) + 1\n",
    "index2word = {v:k for k, v in word2index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ii in range(len(Marie)):\n",
    "    Marie.loc[ii,\"Points1\"] = int(Marie.loc[ii,\"points\"])/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs, ys = [], []\n",
    "\n",
    "for iii in range(len(Marie)):\n",
    "    sentence = Marie['POS-Tag'][iii]\n",
    "    label = float(Marie['Points1'][iii])\n",
    "    words = [x.lower() for x in nltk.word_tokenize(sentence)]\n",
    "    ys.append((label))\n",
    "    wids = [word2index[word] for word in words]\n",
    "    xs.append(wids)\n",
    "\n",
    "X = pad_sequences(xs, maxlen=maxlen)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, ys, test_size=0.3, random_state=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bidirectional LSTM improve accuracy\n",
    "from keras.layers.wrappers import Bidirectional\n",
    "from keras.layers import RepeatVector\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.constraints import maxnorm\n",
    "\n",
    "\n",
    "\n",
    "HIDDEN_LAYER_SIZE = 500\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, EMBED_SIZE,input_length=maxlen))\n",
    "model.add(SpatialDropout1D(0.3))\n",
    "model.add(Bidirectional(LSTM(HIDDEN_LAYER_SIZE, dropout=0.2, recurrent_dropout=0.2, kernel_regularizer='l2')))\n",
    "model.add(RepeatVector(maxlen))\n",
    "model.add(Bidirectional(LSTM(HIDDEN_LAYER_SIZE, return_sequences=False)))\n",
    "#model.add(TimeDistributed(Dense(1)))\n",
    "model.add(Dense(512, activation='relu', kernel_constraint=maxnorm(3)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256, activation='relu', kernel_constraint=maxnorm(3)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "NUM_EPOCHS = 10\n",
    "lr = 0.1\n",
    "decay = lr/NUM_EPOCHS\n",
    "sgd = optimizers.SGD(lr= lr, decay=decay, momentum = 0.9, nesterov = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "def RawDiff(y_true, y_pred):\n",
    "    return ((y_pred)- (y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mean_squared_error\", optimizer=sgd, metrics=[\"mae\", \"acc\", RawDiff])\n",
    "history1 = model.fit(Xtrain, Ytrain, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS, validation_data=(Xtest, Ytest))\n",
    "\n",
    "scores = model.evaluate(Xtest, Ytest, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[2]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(212)\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(history1.history1[\"loss\"], color=\"g\", label=\"Train\")\n",
    "plt.plot(history1.history1[\"val_loss\"], color=\"b\", label=\"Validation\")\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "\n",
    "plt.subplot(211)\n",
    "plt.title(\"Mean_Absolute_Error\")\n",
    "plt.plot(history1.history1[\"mean_absolute_error\"], color=\"g\", label=\"Train\")\n",
    "plt.plot(history1.history1[\"val_mean_absolute_error\"], color=\"b\", label=\"Validation\")\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "#plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

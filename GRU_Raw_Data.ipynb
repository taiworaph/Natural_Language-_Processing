{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taiwoalabi/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#This code is to implement RNN (Recurrent Neural Networks for sentiment analysis)\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers import GRU\n",
    "\n",
    "from keras.layers.core import Dense, Dropout, SpatialDropout1D, Activation\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.pooling import GlobalMaxPooling1D\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gensim, logging\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_FILE = \"/Users/taiwoalabi/Downloads/winemag-data-130k-v2.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Marie= pd.read_csv(INPUT_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Marie[\"Feature1\"] = []\n",
    "for ii in range(len(Marie)):\n",
    "    \n",
    "    Marie.loc[ii,\"Feature1\"] = str(Marie.loc[ii,\"description\"]) + \",\" + str(Marie.loc[ii,\"country\"]) + \",\" + str(Marie.loc[ii,\"province\"]) \\\n",
    "    + str(Marie.loc[ii,\"variety\"]) + \",\" + str(Marie.loc[ii,\"winery\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 5000\n",
    "EMBED_SIZE = 500\n",
    "NUM_FILTERS = 1024\n",
    "NUM_WORDS = 70\n",
    "BATCH_SIZE = 100\n",
    "NUM_EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = collections.Counter()\n",
    "maxlen = 0\n",
    "for iii in range(len(Marie)):\n",
    "    sentence = Marie['Feature1'][iii]\n",
    "    words = [x.lower() for x in nltk.word_tokenize(sentence)]\n",
    "    \n",
    "    if len(words) > maxlen:\n",
    "        maxlen = len(words)\n",
    "    for word in words:\n",
    "        counter[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2index = collections.defaultdict(int)\n",
    "for wid, word in enumerate(counter.most_common(VOCAB_SIZE)):\n",
    "    word2index[word[0]] = wid + 1\n",
    "vocab_size = len(word2index) + 1\n",
    "index2word = {v:k for k, v in word2index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ii in range(len(Marie)):\n",
    "    Marie.loc[ii,\"Points1\"] = int(Marie.loc[ii,\"points\"])/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs, ys = [], []\n",
    "\n",
    "for iii in range(len(Marie)):\n",
    "    sentence = Marie['Feature1'][iii]\n",
    "    label = float(Marie['Points1'][iii])\n",
    "    words = [x.lower() for x in nltk.word_tokenize(sentence)]\n",
    "    ys.append((label))\n",
    "    wids = [word2index[word] for word in words]\n",
    "    xs.append(wids)\n",
    "\n",
    "X = pad_sequences(xs, maxlen=maxlen)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, ys, test_size=0.3, random_state=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 162, 500)          2500500   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_1 (Spatial (None, 162, 500)          0         \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 162, 500)          1501500   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 162, 500)          0         \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 500)               1501500   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               256512    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 5,891,597\n",
      "Trainable params: 5,891,597\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Bidirectional LSTM improve accuracy\n",
    "from keras.layers.wrappers import Bidirectional\n",
    "from keras.layers import RepeatVector\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.constraints import maxnorm\n",
    "\n",
    "\n",
    "\n",
    "HIDDEN_LAYER_SIZE = 500\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, EMBED_SIZE,input_length=maxlen))\n",
    "model.add(SpatialDropout1D(0.3))\n",
    "model.add(GRU(HIDDEN_LAYER_SIZE, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(GRU(HIDDEN_LAYER_SIZE, return_sequences=False))\n",
    "#model.add(TimeDistributed(Dense(1)))\n",
    "model.add(Dense(512, activation='relu', kernel_constraint=maxnorm(3)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256, activation='relu', kernel_constraint=maxnorm(3)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "NUM_EPOCHS = 10\n",
    "lr = 0.001\n",
    "decay = lr/NUM_EPOCHS\n",
    "sgd = optimizers.SGD(lr= lr, decay=decay, momentum = 0.9, nesterov = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "def RawDiff(y_true, y_pred):\n",
    "    return ((y_pred)- (y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Variable *= will be deprecated. Use variable.assign_mul if you want assignment to the variable value or 'x = x * y' if you want a new python Tensor object.\n",
      "Train on 90979 samples, validate on 38992 samples\n",
      "Epoch 1/10\n",
      "90979/90979 [==============================] - 6168s 68ms/step - loss: 0.0196 - mean_absolute_error: 0.0819 - acc: 1.5388e-04 - RawDiff: -0.0272 - val_loss: 9.6924e-04 - val_mean_absolute_error: 0.0251 - val_acc: 1.0259e-04 - val_RawDiff: -0.0044\n",
      "Epoch 2/10\n",
      "90979/90979 [==============================] - 6173s 68ms/step - loss: 0.0032 - mean_absolute_error: 0.0452 - acc: 1.6487e-04 - RawDiff: -0.0050 - val_loss: 9.5288e-04 - val_mean_absolute_error: 0.0249 - val_acc: 1.0259e-04 - val_RawDiff: -0.0050\n",
      "Epoch 3/10\n",
      "90979/90979 [==============================] - 6116s 67ms/step - loss: 0.0023 - mean_absolute_error: 0.0379 - acc: 1.6487e-04 - RawDiff: -0.0032 - val_loss: 9.5326e-04 - val_mean_absolute_error: 0.0249 - val_acc: 1.0259e-04 - val_RawDiff: -0.0057\n",
      "Epoch 4/10\n",
      "90979/90979 [==============================] - 6485s 71ms/step - loss: 0.0018 - mean_absolute_error: 0.0342 - acc: 1.6487e-04 - RawDiff: -0.0023 - val_loss: 9.4413e-04 - val_mean_absolute_error: 0.0248 - val_acc: 1.0259e-04 - val_RawDiff: -0.0052\n",
      "Epoch 5/10\n",
      "90979/90979 [==============================] - 6840s 75ms/step - loss: 0.0016 - mean_absolute_error: 0.0321 - acc: 1.6487e-04 - RawDiff: -0.0018 - val_loss: 9.4156e-04 - val_mean_absolute_error: 0.0247 - val_acc: 1.0259e-04 - val_RawDiff: -0.0051\n",
      "Epoch 6/10\n",
      "90979/90979 [==============================] - 6919s 76ms/step - loss: 0.0015 - mean_absolute_error: 0.0307 - acc: 1.6487e-04 - RawDiff: -0.0015 - val_loss: 9.4005e-04 - val_mean_absolute_error: 0.0247 - val_acc: 1.0259e-04 - val_RawDiff: -0.0049\n",
      "Epoch 7/10\n",
      "90979/90979 [==============================] - 8462s 93ms/step - loss: 0.0014 - mean_absolute_error: 0.0297 - acc: 1.6487e-04 - RawDiff: -0.0012 - val_loss: 9.3673e-04 - val_mean_absolute_error: 0.0247 - val_acc: 1.0259e-04 - val_RawDiff: -0.0046\n",
      "Epoch 8/10\n",
      "90979/90979 [==============================] - 6924s 76ms/step - loss: 0.0013 - mean_absolute_error: 0.0290 - acc: 1.6487e-04 - RawDiff: -0.0011 - val_loss: 9.2811e-04 - val_mean_absolute_error: 0.0246 - val_acc: 1.0259e-04 - val_RawDiff: -0.0037\n",
      "Epoch 9/10\n",
      " 9600/90979 [==>...........................] - ETA: 1:34:51 - loss: 0.0013 - mean_absolute_error: 0.0292 - acc: 2.0833e-04 - RawDiff: -0.0014"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mean_squared_error\", optimizer=sgd, metrics=[\"mae\", \"acc\", RawDiff])\n",
    "history = model.fit(Xtrain, Ytrain, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS, validation_data=(Xtest, Ytest))\n",
    "\n",
    "scores = model.evaluate(Xtest, Ytest, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[2]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(212)\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(history.history[\"loss\"], color=\"g\", label=\"Train\")\n",
    "plt.plot(history.history[\"val_loss\"], color=\"b\", label=\"Validation\")\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "\n",
    "plt.subplot(211)\n",
    "plt.title(\"Mean_Absolute_Error\")\n",
    "plt.plot(history.history[\"mean_absolute_error\"], color=\"g\", label=\"Train\")\n",
    "plt.plot(history.history[\"val_mean_absolute_error\"], color=\"b\", label=\"Validation\")\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "#plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
